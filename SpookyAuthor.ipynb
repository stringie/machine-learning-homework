{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целта на задачата беше да подобрим резултата на лекции (-0.422).\n",
    "Зареждаме сет-а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"/home/string/dev/machine-learning/supervised-learning/strain.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успях да подобря резултата -> (-0.375). Мисля че е добро подобрение считайки колко малко трябваше да променя за да се стигне до него.\n",
    "Премахнах от хиперпараметрите на Vectorizer-a max_df и min_df, което означава че са сложени по default на 1.0 и 1 и това даде доста голямо подобрение. ngram_range си се оказа оптимално, също така и lowercase=False. пробвах със други Naive Bayes модели, но MultinomialNB работеше по добре, и то със alpha=0.03, давайки малко подобрение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Накрая реших да погледна кои са другите хиперпараметри на vectorizer-a, тъй кате те направиха най големите подобрения. Единствено реших да пробвам token_pattern=’(?u)\\b\\w\\w+\\b’, какви думи взима като regex, и видях че не взима точно всичко от изречението. Затова за да генерализирам още подадох на token_pattern '\\w+' да взима просто всичко което е дума. Това даде също добро подобрение и с това спрях да пробвам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85523897  0.85366227  0.85318008]\n",
      "[-0.3747073  -0.37280312 -0.3782487 ]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2), lowercase=False, sublinear_tf=True, token_pattern=r'\\w+')),\n",
    "    ('nb', MultinomialNB(alpha=0.03))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe, train.text, train.author, cv=3, n_jobs=4))\n",
    "print(cross_val_score(pipe, train.text, train.author, cv=3, n_jobs=4, scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train.text, train.author)\n",
    "test = pd.read_csv(\"/home/string/dev/machine-learning/supervised-learning/stest.csv\", index_col='id')\n",
    "result = pipe.predict_proba(test.text.values)\n",
    "pd.DataFrame(result, index=test.index, columns=authors).to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Със този модел в kaggle получавам score от 0.33 и бях на 106 място. Може да не съм правил много графики или разсъждения в този notebook но задачата е изпълнена :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
